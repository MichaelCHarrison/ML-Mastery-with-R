---
title: "ML Mastery with R - Chapter 7"
output: html_notebook
---

Understanding data using descriptive statistics

*Looking at your data*
```{r}
library(mlbench)
data("PimaIndiansDiabetes")
head(PimaIndiansDiabetes, 20)
```

*Check Dimensions*
```{r}
dim(PimaIndiansDiabetes)
```


*Check data types*
```{r}
data("BostonHousing")
sapply(BostonHousing, class)
```

*Check class distribution*

- Checking the proportion of instances that belong to each class label
        - can highlight the imablnace in the data
- In the case of a multiclass classification problem it may expose a class with a small number of instances that may be candidates for removing from the dataset

```{r}
y <- PimaIndiansDiabetes$diabetes
cbind(freq = table(y), percentage= prop.table(table(y))*100)
```

*Data Summary*

```{r}
summary(iris)
```

*Checking standard deviations*

- summary() does not include sd 
        - can be used to remove outliers for any values sitting more than 3 times the sd 
        from the mean

```{r}
sapply(PimaIndiansDiabetes[,1:8], sd)
```

*Checking for Skewness*

- If distribution looks nearly-Gaussian but is pushed left or right it is useful to know the skew
- easier to detect visually, but hard to tell through means, sd, and quartile statistics
        - skew gives reference that you can use later if you decide to correct the skew 
        for an attribute
- The further the distribution of the skew value from zero, the large the skew to the left (negative skew value) or right (positive skew value)

```{r}
library(e1071)
skew <- apply(PimaIndiansDiabetes[,1:8], 2, skewness)
print(skew)
```


*Checking for correlations*
- important to observe and think about how attributes relate to each other

```{r}
correlations <- cor(PimaIndiansDiabetes[,1:8])
correlations
```

